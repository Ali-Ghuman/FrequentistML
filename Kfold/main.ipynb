{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECE475 Frequentist Machine Learning <br>\n",
    "Project 3: Model Assessment and Selection  <br> \n",
    "Ali Ghuman, Layth Yassin, Simon Yoon <br>\n",
    "\n",
    "The project demonstates correct and incorrect use of k-fold cross-validation. One run uses the whole dataset to perform feature selection without augmentation, then uses cross-validation to test the KNN model. Because all of the data was used for feature selection, the test data influences the model's accuracy without validation. The second run also uses cross-validation prior, but selects the best features based on the unique training data for each fold in the cross-validation. This allows for feature selection without compromising the integrity of the test. The demonstration reveals the significant inaccuracies that can occur without proper model assessment and data usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGES = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 19], [19, 20], [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 30], [30, 31], [31, 32], [32, 33], [33, 34], [34, 35], [35, 36], [36, 37], [37, 38], [38, 39], [39, 40], [40, 41], [41, 42], [42, 43], [43, 44], [44, 45], [45, 46], [46, 47], [47, 48], [48, 49], [49, 50]]\n",
    "# print([ [i, i + 1] for i in range(50)])\n",
    "\n",
    "def percent_accuracy(ds, model): # returns acc \n",
    "    X = ds[0]\n",
    "    y = ds[1]\n",
    "    y_hat = model.predict(X.reshape(1, -1))\n",
    "    return y == y_hat\n",
    "        \n",
    "def correlation(ds): # returns corr of feature vs output\n",
    "    X = ds[0]\n",
    "    y = ds[1]\n",
    "    df1 = pd.DataFrame(X)\n",
    "    df2 = pd.DataFrame(np.array([y for i in range(len(X[0]))]).T)\n",
    "    corr = df1.corrwith(df2)\n",
    "    return corr\n",
    "\n",
    "def best_predictors(ds, x): # return ind of x best predictors\n",
    "    corr = pd.Series(correlation(ds))\n",
    "    corr = corr.abs()\n",
    "    best = corr.nlargest(x, 'all')\n",
    "    best = best.index.values\n",
    "    return best\n",
    "\n",
    "def select_features(ds, best): # return augmented dataset with selected features\n",
    "    X = np.transpose(ds[0])\n",
    "    X_new = []\n",
    "    for i in best:\n",
    "        X_new.append(X[i])\n",
    "    X = np.transpose(X_new)\n",
    "    ds=[X, ds[1]]\n",
    "    return ds\n",
    "\n",
    "def split_data(ds, r): # return list of ranges of k subset\n",
    "    X1 = np.delete(ds[0], r[0], axis = 0)\n",
    "    y1 = np.delete(ds[1], r[0])\n",
    "    ds1 = [X1, y1]\n",
    "    \n",
    "    X2 = ds[0][r[0]]\n",
    "    y2 = [ds[1][r[0]]]\n",
    "    ds2 = [X2, y2]\n",
    "    return [ds1, ds2]\n",
    "\n",
    "def test_model(ds, k, n, x=0): # returns average k-fold acc of knn model\n",
    "    accuracy = 0\n",
    "    for r in RANGES:\n",
    "        data = split_data(ds, r)\n",
    "        #right way\n",
    "        if (x!=0):\n",
    "            best = best_predictors(data[0], x) \n",
    "            ds1 = select_features(data[0], best)\n",
    "            ds2 = select_features(data[1], best)\n",
    "        #wrong way\n",
    "        else:\n",
    "            ds1 = data[0] \n",
    "            ds2 = data[1]\n",
    "        model = KNeighborsClassifier(n_neighbors=n).fit(ds1[0], ds1[1])\n",
    "        y_hat = model.predict(ds2[0].reshape(1, -1))\n",
    "        accuracy += (ds2[1] == y_hat)[0] * 100 \n",
    "    return (accuracy/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wrong way:\n",
      "Accuracy: 100.0%\n",
      "\n",
      "The right way:\n",
      "Accuracy: 64.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 50 # folds in cross-validation\n",
    "n = 1 # nearest neighbors \n",
    "x = 100 # best predictor count\n",
    "ds = make_classification(n_samples=50, n_features=5000) # test\n",
    "\n",
    "print(\"The wrong way:\")\n",
    "best = best_predictors(ds, x)\n",
    "ds_alt = select_features(ds, best)\n",
    "accuracy = test_model(ds_alt, k, n, 0)\n",
    "print(\"Accuracy: \"+str(accuracy)+\"%\")\n",
    "print()\n",
    "\n",
    "print(\"The right way:\")\n",
    "accuracy = test_model(ds, k, n, x)\n",
    "print(\"Accuracy: \" + str(accuracy) + \"%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52263d31e0ea6b231aec245f99a4cffc90f185b568428f4efb79c2d6c054be4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
