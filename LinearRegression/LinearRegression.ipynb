{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y, y_hat):\n",
    "    return np.mean(np.square(np.array(y-y_hat)))\n",
    "\n",
    "class LinearModel:\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "\n",
    "    def fit(self, x,y):\n",
    "        X = np.concatenate((np.ones((x.shape[0], 1)), x), axis = 1)\n",
    "        self.beta = np.linalg.solve((X.T @ X),X.T @ y)\n",
    "        return self.beta\n",
    "\n",
    "    def predict(self,x, with_intercept = True):\n",
    "        if with_intercept:\n",
    "            X = np.concatenate((np.ones((x.shape[0], 1)),x), axis = 1)\n",
    "            y_hat = X @ self.beta\n",
    "        else:\n",
    "            y_hat = x @ self.beta[1:]\n",
    "        return y_hat\n",
    "class RidgeModel(LinearModel):\n",
    "  def __init__(self, lambd):\n",
    "    self.lambd = lambd\n",
    "    self.beta = None\n",
    "\n",
    "  def fit(self, x,y):\n",
    "    X = np.concatenate((np.ones((x.shape[0], 1)),x), axis = 1)\n",
    "    self.beta  = np.linalg.solve(X.T @ X + self.lambd*np.eye(X.shape[1]),X.T@y)\n",
    "    return self.beta\n",
    "\n",
    "def weighted_error(lam, y, y_hat, beta):\n",
    "  return mean_square_error(y, y_hat) + lam*np.sum(np.array(beta[1:])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(x, y, test_percent, val_percent, random_state = None):\n",
    "    rel_val_percent = np.round((val_percent)/(1-test_percent), 2)\n",
    "\n",
    "    x_inter, x_test, y_inter, y_test = train_test_split(x, y, test_size = test_percent, random_state = random_state)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_inter, y_inter, test_size = rel_val_percent, random_state = random_state)\n",
    "    \n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "def normalize(x_train, x_val, x_test): \n",
    "    x_train = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "    x_val = (x_val - x_val.mean(axis=0)) / x_val.std(axis=0)\n",
    "    x_test = (x_test - x_test.mean(axis=0)) / x_test.std(axis=0)\n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "def predict(x_train, y_train, x_test, y_test, linearModel): \n",
    "    beta = linearModel.fit(x_train, y_train)\n",
    "    test_error = mean_square_error(y_test, linearModel.predict(x_test))\n",
    "    train_error = mean_square_error(y_train, linearModel.predict(x_train))\n",
    "    print(\"Test MSE:\", test_error)\n",
    "    print('\\n')\n",
    "    return beta\n",
    "\n",
    "def format_corr_table(corr_mat, coeff_names):\n",
    "  corr_table = []\n",
    "  for row_num in range(corr_mat.shape[0]):\n",
    "    vals = list(corr_mat[row_num, :])\n",
    "    vals = [str(round(val,3)) for val in vals]\n",
    "    vals.insert(0,coeff_names[row_num])\n",
    "    vals = vals [:row_num+1]\n",
    "    corr_table.append(vals)\n",
    "  return corr_table\n",
    "\n",
    "WHICH_DATASET = 0\n",
    "\n",
    "def correlation_table(x_train, df): \n",
    "    corr_mat = np.corrcoef(x_train.T)\n",
    "    coeff_names = list(df.columns.values[:-1])\n",
    "    corr_table = format_corr_table(corr_mat, coeff_names)\n",
    "    coeff_names.insert(0,'Coefficients')\n",
    "    corr = tabulate(corr_table[1:], headers=coeff_names, tablefmt='pretty')\n",
    "    if WHICH_DATASET == 0:\n",
    "      print('     Table 1: Correlations of predictors in the prostate cancer data.')\n",
    "      WHICH_DATASET = 1\n",
    "    elif WHICH_DATASET == 1:\n",
    "      print('     Table 1: Correlations of predictors in the real estate data')\n",
    "    print(corr)\n",
    "    print('\\n')\n",
    "\n",
    "def z_scorer(model, X, y):\n",
    "    N = len(X)\n",
    "    p = X.shape[1]\n",
    "    sigma =  np.sqrt(np.sum((y - model.predict(X))**2)/(N-p-1))\n",
    "    X = np.concatenate((np.ones((N, 1)),X), axis = 1)\n",
    "    sqrt_v = np.sqrt(np.diagonal(np.linalg.inv(X.T @ X)))\n",
    "    standard_error = sigma*sqrt_v\n",
    "    z_score = model.beta/standard_error\n",
    "    return standard_error, z_score\n",
    "\n",
    "def format_lin_summary_table(term, beta, s_e, z_scr, round_decimal = 2):\n",
    "  summary_mat = []\n",
    "  for coeff_num in range(len(term)):\n",
    "    row = list([term[coeff_num],\n",
    "              round(beta[coeff_num], round_decimal),\n",
    "              round(s_e[coeff_num], round_decimal),\n",
    "              round(z_scr[coeff_num], round_decimal)])\n",
    "    summary_mat.append(row)\n",
    "  return summary_mat\n",
    "\n",
    "\n",
    "def stats_table(linearModel, x_train, y_train, beta, df):\n",
    "    standard_error, Z_score = z_scorer(linearModel, x_train, y_train)\n",
    "    term = list(df.columns.values[:-1])\n",
    "    term.insert(0, 'Intercept')\n",
    "    summary_lst = format_lin_summary_table(term, beta, standard_error, Z_score)\n",
    "    summary_header = ['Term', 'Coefficient', 'Std. Error', 'Z Score']\n",
    "    summary = tabulate(summary_lst, headers = summary_header, tablefmt='pretty')\n",
    "    if WHICH_DATASET == 0:\n",
    "      print('Table 2: Linear model fit to the prostate cancer data.')\n",
    "      WHICH_DATASET = 1\n",
    "    elif WHICH_DATASET == 1:\n",
    "      print('Table 2: Linear model fit to the real estate data')\n",
    "    print(summary)\n",
    "    print('\\n')\n",
    "\n",
    "def perform_linear_regression(x_train, y_train, x_test, y_test, df): \n",
    "    #prediction\n",
    "    linearModel = LinearModel()\n",
    "    beta = predict(x_train, y_train, x_test, y_test, linearModel)\n",
    "\n",
    "    #table 3.1\n",
    "    correlation_table(x_train, df)\n",
    "    \n",
    "    #table 3.2\n",
    "    stats_table(linearModel, x_train, y_train, beta, df)\n",
    "\n",
    "def get_weights(Lassomodel):\n",
    "  wght = np.zeros((len(Lassomodel.coef_)+1))\n",
    "  wght[0] = Lassomodel.intercept_\n",
    "  wght[1:] = Lassomodel.coef_\n",
    "  return list(wght)\n",
    "\n",
    "def optimize_parameter(model, param_range, X_train, y_train, X_val, y_val, df):\n",
    "  best_val_err = float('inf')\n",
    "  opt_param = None\n",
    "  weights = {}\n",
    "\n",
    "  for param in param_range:\n",
    "    newmodel = model(param)\n",
    "    newmodel.fit(X_train,y_train)\n",
    "    try: \n",
    "      weights[param] = list(newmodel.beta)\n",
    "    except: \n",
    "      newmodel.fit(X_train,y_train)\n",
    "      weights[param] = get_weights(newmodel)\n",
    "\n",
    "    err_val = weighted_error(param, y_val, newmodel.predict(X_val), weights[param])\n",
    "    if err_val < best_val_err: \n",
    "      best_val_err = err_val\n",
    "      opt_param = param\n",
    "\n",
    "  return opt_param, best_val_err, weights\n",
    "\n",
    "def perform_ridge_regression(x_train, y_train, x_test, y_test, x_val, y_val, df):\n",
    "    N = 1000\n",
    "    lamrange = np.logspace(-9, 4, N)\n",
    "\n",
    "    opt_lambda_ridge, valMSE_ridge, weights = optimize_parameter(RidgeModel,\n",
    "                                                             lamrange,\n",
    "                                                             x_train,\n",
    "                                                             y_train,\n",
    "                                                             x_val,\n",
    "                                                             y_val, df)\n",
    "\n",
    "    opt_ridgemodel = RidgeModel(opt_lambda_ridge)\n",
    "    opt_beta_ridge = opt_ridgemodel.fit(x_train, y_train)\n",
    "    \n",
    "    test_error_ridge = mean_square_error(y_test, opt_ridgemodel.predict(x_test))\n",
    "    train_error_ridge = mean_square_error(y_train, opt_ridgemodel.predict(x_train))\n",
    "    \n",
    "    print('MSE from test data:',test_error_ridge)\n",
    "    print('\\n')\n",
    "\n",
    "    p = len(weights[lamrange[0]])\n",
    "    coeffs = np.zeros((N,p))\n",
    "\n",
    "    for i in range(len(lamrange)):\n",
    "        coeffs[i,:] = weights[lamrange[i]]\n",
    "\n",
    "    term = list(df.columns.values[:-1])\n",
    "    term.insert(0, 'Intercept')\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(15,7.5),) \n",
    "    ax = plt.gca()\n",
    "    for i in range(p):\n",
    "        ax.plot(lamrange,coeffs[:,i])\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(ax.get_xlim()[::-1])  \n",
    "    if WHICH_DATASET == 0:\n",
    "      plt.title('Figure 1: Profiles of ridge coefficients for the prostate cancer example, as the tuning parameter λ is varied')\n",
    "      WHICH_DATASET = 1\n",
    "    elif WHICH_DATASET == 1:\n",
    "      plt.title('Figure 1: Profiles of ridge coefficients for the real estate example as the tuning parameter λ is varied')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.xlabel('$\\lambda$')\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.legend(term, bbox_to_anchor=(1.05, 1), loc='upper left',)\n",
    "    plt.ylim([ymin,ymax])\n",
    "\n",
    "    plt.vlines(opt_lambda_ridge, ymin, ymax, linestyle='dashed', colors='red')\n",
    "    plt.show()\n",
    "    print('\\nBest lambda found:', opt_lambda_ridge)\n",
    "\n",
    "def perform_lasso_regression(x_train, y_train, x_test, y_test, x_val, y_val, df):\n",
    "    N = 1000\n",
    "    alpharange = np.logspace(-9, 2, N)\n",
    "\n",
    "    opt_alpha_lasso, valMSE_lasso,weights_lasso = optimize_parameter(lm.Lasso,\n",
    "                                                                    alpharange,\n",
    "                                                                    x_train,\n",
    "                                                                    y_train,\n",
    "                                                                    x_val,\n",
    "                                                                    y_val, df)\n",
    "    #generating a model using the optimal alpha\n",
    "    opt_lassomodel = lm.Lasso(alpha = opt_alpha_lasso)\n",
    "    opt_lassomodel.fit(x_train,y_train)\n",
    "\n",
    "    #MSEs\n",
    "    testMSE_lasso= mean_square_error(y_test, opt_lassomodel.predict(x_test))\n",
    "    trainMSE_lasso = mean_square_error(y_train, opt_lassomodel.predict(x_train))\n",
    "\n",
    "    #printing MSE\n",
    "    print('MSE from test data:', testMSE_lasso)\n",
    "\n",
    "    #initialize \n",
    "    p = 9 if df.columns[0] == 'lcavol' else 7\n",
    "    coeffs = np.zeros((N, p))\n",
    "    # coeff for each df\n",
    "    for i in range(len(alpharange)):\n",
    "        coeffs[i,:] = weights_lasso[alpharange[i]]\n",
    "    \n",
    "    # Plotting\n",
    "    term = list(df.columns.values[:-1])\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(15,7.5)) \n",
    "    for i in range(0,p):\n",
    "        plt.plot(alpharange,coeffs[:,i])\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.title('Figure 2: Profiles of lasso coefficients.')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.xlabel('$\\lambda$')\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.legend(term, bbox_to_anchor=(1.05, 1), loc='upper left',)\n",
    "    plt.ylim([ymin,ymax])\n",
    "\n",
    "\n",
    "    #adding a line for the best lambda value\n",
    "    plt.vlines(opt_alpha_lasso, ymin, ymax, linestyle='dashed', colors='red')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #print the best lambda value\n",
    "    print('Best alpha found:', opt_alpha_lasso)\n",
    "\n",
    "def perform_analysis(x, y, df): \n",
    "    #training/validation/test setup\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = train_val_test_split(x, y, 0.1, 0.1, np.random.randint(1, 31475 + 1))\n",
    "\n",
    "    #normalize\n",
    "    x_train, x_val, x_test = normalize(x_train, x_val, x_test)\n",
    "\n",
    "    perform_linear_regression(x_train, y_train, x_test, y_test, df)\n",
    "    perform_ridge_regression(x_train, y_train, x_test, y_test, x_val, y_val, df)\n",
    "    perform_lasso_regression(x_train, y_train, x_test, y_test, x_val, y_val, df)\n",
    "    baseline = np.mean(y_train)\n",
    "    baselineMSE = mean_square_error(y_train, baseline)\n",
    "    print(f'Baseline MSE: {baselineMSE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate = pd.read_csv('prostate.data',\n",
    "                 delimiter='\\t',\n",
    "                 index_col = 0)\n",
    "df_prostate = df_prostate.iloc[:,:-1]\n",
    "prostate_data = df_prostate.to_numpy().astype('float')\n",
    "df_estate = pd.read_csv(\"Real estate.csv\")\n",
    "\n",
    "df_estate = df_estate.iloc[:,:-1]\n",
    "estate_data = df_estate.to_numpy().astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_analysis(prostate_data[:,:-1], prostate_data[:,-1], df_prostate)\n",
    "perform_analysis(estate_data[:,:-1], estate_data[:,-1], df_estate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4564dc58dfc4f7da65a8596492a0cea475f3de274280957854699bb731551874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
