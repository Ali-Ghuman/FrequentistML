{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import NMF\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ali Ghuman, Layth Yassin, Simon Yoon \n",
    "\n",
    "A recommendation was expertly curated for a suggestive dataset of 100k movie ratings. A technique known as grid search was employed with an extensive variety of hyperparameter values, specifically 486, to find the optimal values. The root mean squared that reigned supreme was 0.954 (compared to 0.963 baseline) with the following values for the hyperparameters: \n",
    "> 20 epochs\n",
    "> 25 latent dimensions\n",
    "> 0.06 regularization term for users\n",
    "> 0.36 regularization term for items\n",
    "> 0.02 regulatization term for user bias\n",
    "> 0.005 regulatization term for item bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540216296692338 {'n_epochs': 20, 'n_factors': 25, 'reg_pu': 0.06, 'reg_qi': 0.36, 'reg_bu': 0.02, 'reg_bi': 0.005}\n"
     ]
    }
   ],
   "source": [
    "n_epochs = [10, 20]\n",
    "n_factors = [5, 25, 50]\n",
    "reg_pu = [0.02, 0.06, 0.36]\n",
    "reg_qi = [0.02, 0.06, 0.36]\n",
    "reg_bu = [0.005, 0.02, 0.12]\n",
    "reg_bi = [0.005, 0.02, 0.12]\n",
    "\n",
    "gs = GridSearchCV(NMF, {\"n_epochs\": n_epochs, \"n_factors\": n_factors, \n",
    "                \"reg_pu\": reg_pu, \"reg_qi\": reg_qi,\n",
    "                \"reg_bu\": reg_bu, \"reg_bi\": reg_bi}, measures=[\"rmse\"])\n",
    "gs.fit(Dataset.load_builtin('ml-100k'))\n",
    "print(gs.best_score[\"rmse\"], gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procure_loss(P, U, df, hash_map_item, movie_map):\n",
    "    loss = 0\n",
    "    for i, row in df.iterrows():\n",
    "        i = hash_map_item[int(row[\"userId\"])]\n",
    "        j = movie_map[int(row[\"movieId\"])]\n",
    "        loss += (row[\"rating\"] - U[i, :] @ P[j, :]) ** 2 + 0.001 * (np.linalg.norm(U[i, :]) + np.linalg.norm(P[j, :]) )\n",
    "    return loss\n",
    "\n",
    "def get_r(df: pd.DataFrame, num_item, hash_map_item, flag) -> np.ndarray:\n",
    "    r = np.zeros((num_item, 1))\n",
    "    for k, row in df.iterrows():\n",
    "        i = int(row[\"userId\"]) if flag else row[\"movieId\"]\n",
    "        i = hash_map_item[i]\n",
    "        r[i] = row[\"rating\"]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ml-latest-small/ratings.csv\").drop(\"timestamp\", axis = 1)\n",
    "\n",
    "df = df[df[\"userId\"] < 200]\n",
    "df = df[df[\"movieId\"] < 100]\n",
    "\n",
    "user_ids = np.sort(df[\"userId\"].unique())\n",
    "movie_ids = np.sort(df[\"movieId\"].unique())\n",
    "\n",
    "num_users = user_ids.shape[0]\n",
    "num_movies = movie_ids.shape[0]\n",
    "\n",
    "hash_map_movies = {}\n",
    "for i in range(num_movies):\n",
    "    if movie_ids[i] not in hash_map_movies:\n",
    "        hash_map_movies[movie_ids[i]] = i\n",
    "\n",
    "hash_map_users = {}\n",
    "for i in range(num_users):\n",
    "    if user_ids[i] not in hash_map_users:\n",
    "        hash_map_users[user_ids[i]] = i\n",
    "\n",
    "latent_var  = 10\n",
    "user_matrix = np.random.uniform(0, 1, (num_users, latent_var))\n",
    "movie_matrix = np.random.uniform(0, 1, (num_movies, latent_var))\n",
    "\n",
    "loss = np.zeros(df.shape[0])\n",
    "loss_counter = 0\n",
    "for i, row in df.iterrows():\n",
    "    user_ratings = df[df[\"userId\"] == row[\"userId\"]]\n",
    "    r_user = get_r(user_ratings, num_movies, hash_map_movies, 0)\n",
    "    user_matrix_row_updated = np.linalg.inv(movie_matrix.T @ movie_matrix + 0.001 * np.identity(movie_matrix.shape[1])) @ movie_matrix.T @ r_user\n",
    "    k = hash_map_users[int(row[\"userId\"])]\n",
    "    user_matrix[k, :] = user_matrix_row_updated.flatten()\n",
    "\n",
    "    movie_ratings = df[df[\"movieId\"] == row[\"movieId\"]]\n",
    "    r_movie = get_r(movie_ratings, num_users, hash_map_users, 1)\n",
    "    movie_matrix_row_updated = np.linalg.inv(user_matrix.T @ user_matrix + 0.001 * np.identity(user_matrix.shape[1])) @ user_matrix.T @ r_movie\n",
    "    k = hash_map_movies[int(row[\"movieId\"])]\n",
    "    movie_matrix[k, :] = movie_matrix_row_updated.flatten()\n",
    "\n",
    "    loss[loss_counter] = procure_loss(movie_matrix, user_matrix, df, hash_map_users, hash_map_movies)\n",
    "    loss_counter += 1\n",
    "plt.figure()\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
